{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Classifier (PyTorch - BERT).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f0db11d670ff40c98b8db40ecb66f231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6fd4747f26284757afb6e7f0f086bbb8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_235129fa92bf4aa1b5394f745ed69dd9",
              "IPY_MODEL_fea9f8193c2c4347922f3317c306ba3c"
            ]
          }
        },
        "6fd4747f26284757afb6e7f0f086bbb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "235129fa92bf4aa1b5394f745ed69dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f4308f25ea3849dc88015b83cc4899ad",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7348f3c38a8f45b9a607206ab27a9cf9"
          }
        },
        "fea9f8193c2c4347922f3317c306ba3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5cb5ebbffd7848cdae049bf9f25f8a77",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [01:34&lt;00:00, 4.56B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa268df151b945f4801d460ae5c40b7e"
          }
        },
        "f4308f25ea3849dc88015b83cc4899ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7348f3c38a8f45b9a607206ab27a9cf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cb5ebbffd7848cdae049bf9f25f8a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa268df151b945f4801d460ae5c40b7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "403f1d2c4724401baa7d84f07662e607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cfe6382465d045ce911526998a6ba530",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9a8fbd22f687472e99687602fcd442f0",
              "IPY_MODEL_2ca68af02e5349c1922a2566dfb2f079"
            ]
          }
        },
        "cfe6382465d045ce911526998a6ba530": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a8fbd22f687472e99687602fcd442f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_37d5a2f3f133406b89b4f94642b50942",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfa5a21043184c48acac534add8d6943"
          }
        },
        "2ca68af02e5349c1922a2566dfb2f079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9ea3762070104b8aa30053a1cb784688",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:06&lt;00:00, 68.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46f1cf49f7384412a0486c30dfa75284"
          }
        },
        "37d5a2f3f133406b89b4f94642b50942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfa5a21043184c48acac534add8d6943": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ea3762070104b8aa30053a1cb784688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46f1cf49f7384412a0486c30dfa75284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK8660tuoog2"
      },
      "source": [
        "#BERT Sentiment Classifier\n",
        "Uses pretrained data along with our data to fine tune birt model.\n",
        "We will use review title with their ratings as separate records, \n",
        "since input to these files are precise, short 'aspect specific' reviews \n",
        "similar to review titles.\n",
        "Further improvement can be achieved by having domain specific models \n",
        "to make them tune better for domain specific aspects \n",
        "As of now, it performs binary classification, but can be used for multiclass classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXFaBqz4orvn"
      },
      "source": [
        "__author__ = 'Sakshi Sehgal'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w1wFlctot5Z",
        "outputId": "5f9188f0-0750-49dc-e221-827eed7eced0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "!pip install transformers\n",
        "\n",
        "#getting the required libraries\n",
        "import transformers \n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#for plotting and tabular visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import class_weight\n",
        "from collections import defaultdict"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 17.6MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 23.5MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 17.2MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 11.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 10.0MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 9.8MB/s eta 0:00:01\r\u001b[K     |█▉                              | 71kB 10.0MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 9.2MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92kB 9.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 102kB 9.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 112kB 9.0MB/s eta 0:00:01\r\u001b[K     |███▏                            | 122kB 9.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 133kB 9.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 143kB 9.0MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 9.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 163kB 9.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 174kB 9.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 184kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 194kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 204kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 215kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 225kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 235kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 245kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 256kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 266kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 276kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 286kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 296kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 307kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 317kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 327kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 337kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 348kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 358kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 368kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 378kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 389kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 399kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 409kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 419kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 430kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 440kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 450kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 460kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 471kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 481kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 491kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 501kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 512kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 522kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 532kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 542kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 552kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 563kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 573kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 583kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 593kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 604kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 614kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 624kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 634kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 645kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 655kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 665kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 675kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 686kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 696kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 706kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 716kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 727kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 737kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 747kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 757kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 768kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 778kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 788kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 798kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 808kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 819kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 829kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 839kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 849kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 860kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 870kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 880kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 890kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 901kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 911kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 921kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 931kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 942kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 952kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 962kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 972kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 983kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 993kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0MB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.0MB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.0MB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.0MB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.0MB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.1MB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.1MB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.1MB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1MB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1MB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1MB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.1MB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.1MB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2MB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2MB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2MB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.2MB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 50.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 57.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 48.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=c819ce71a2e640b64d7e258cf1347a24164abf067c022d24eb8f215fc155d8ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJqYYpPOozd2"
      },
      "source": [
        "#Setting the device and hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-UDqkyuo6uN"
      },
      "source": [
        "#Setting device as per the availability\n",
        "#if CUDA enabled GPU is available then we're going to use that\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "EPOCHS = 5\n",
        "dropout1 = 0.5\n",
        "dropout2 = 0.7\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "PRE_TRAINED_MODEL_NAME_LARGE = 'bert-large-cased'\n",
        "MAX_LEN = 120"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlEfoOr-pA_t"
      },
      "source": [
        "#Model Class and Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XOF06JDpGDk"
      },
      "source": [
        "#class to generate bert encodings\n",
        "#text into numerical vectors using the tokenizer\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self,reviews,targets,tokenizer,max_len):\n",
        "        self.reviews = reviews\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "        review = str(self.reviews[item])\n",
        "        target = self.targets[item]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            review,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            )\n",
        "        \n",
        "        return {\n",
        "            'review_text': review,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'targets': torch.tensor(target, dtype=torch.long)\n",
        "            }\n",
        "\n",
        "#generating data for classifier\n",
        "#Pytorch dataset loader\n",
        "def create_data_loader(df,tokenizer,max_len,batch_size):\n",
        "    ds = ReviewDataset(\n",
        "        reviews = df.review.to_numpy(), \n",
        "        targets = df.rating.to_numpy(),\n",
        "        tokenizer = tokenizer,\n",
        "        max_len=max_len)\n",
        "\n",
        "    return DataLoader(ds,\n",
        "                      batch_size=batch_size,\n",
        "                      num_workers=4)\n",
        "\n",
        "#class to generate bert encodings\n",
        "#text into numerical vectors using the tokenizer\n",
        "class DatasetEncoding(Dataset):\n",
        "    def __init__(self,reviews,targets,tokenizer,max_len):\n",
        "        self.reviews = reviews\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "        review = str(self.reviews[item])\n",
        "        target = self.targets[item]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            review,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            )\n",
        "        \n",
        "        return {\n",
        "            'review_text': review,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'targets': torch.tensor(target, dtype=torch.long)\n",
        "            }\n",
        "\n",
        "class SentimentClassifier(nn.Module):\n",
        "  def __init__(self, n_classes, birt_pretrained = PRE_TRAINED_MODEL_NAME , dropout1 = 0.5, dropout2 = 0.7):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(birt_pretrained)\n",
        "    #0 dropout means no regularization\n",
        "    self.drop = nn.Dropout(p=dropout1)\n",
        "    self.out1 = nn.Linear(self.bert.config.hidden_size, 128)\n",
        "    self.drop1 = nn.Dropout(p=dropout2)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.out = nn.Linear(128, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    output = self.out1(output)\n",
        "    output = self.relu(output)\n",
        "    output = self.drop1(output)\n",
        "    return self.out(output)\n",
        "\n",
        "#function to train our model on each epoch\n",
        "def train_epoch(model,data_loader,loss_fn,optimizer,device,scheduler,n_examples):\n",
        "    model = model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for data in data_loader:\n",
        "        input_ids = data['input_ids'].to(device)\n",
        "        attention_mask = data['attention_mask'].to(device)\n",
        "        targets = data['targets'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "            )\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        loss = loss_fn(outputs,targets)\n",
        "\n",
        "        correct_predictions += torch.sum(preds == targets)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "#function to evaluate the model\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      loss = loss_fn(outputs, targets)\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "def get_test_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(outputs)\n",
        "      real_values.extend(targets)\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values\n",
        "\n",
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('True sentiment')\n",
        "  plt.xlabel('Predicted sentiment')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDCoUQEvpIWq"
      },
      "source": [
        "#Getting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aifzer5epOsJ",
        "outputId": "e677f8d2-b8e0-4fd5-9063-b49aef103ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "'''getting data with ratings\n",
        "for each review, review text and review title are separately considered \n",
        "as review titles mostly talk about 1 aspect (similar to aspect topic sentiment classification) ''' \n",
        "\n",
        "data = pd.read_csv('/content/data.csv', index_col=0).reset_index(drop=True).rename(columns={'Product Rating By Customer':'rating', 'Review Text':'review', 'Review Title':'title'})\n",
        "df1 = pd.DataFrame({'rating': data.rating, 'review': data.review})\n",
        "df2 = pd.DataFrame({'rating': data.rating, 'review': data.title})\n",
        "df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(keep='first', inplace=True)\n",
        "\n",
        "sns.countplot(df.rating)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f345c7f5438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATLklEQVR4nO3df6xf9X3f8ecr/EjShAwy7piDTY1at5PZUshugY2q+aWAQ3+Ydm0EUoObMTl/QAca2wT9Y6TpkDo1CWtSiuQMJ9ClYWwki5uhEJeiRMlCwCYOYCjijsCwS7AbE0IalcnOe398P5a/Mdf+XJP7veea+3xIX33PeZ8f3/f9SvDyOZ9zzjdVhSRJh/OqoRuQJC1+hoUkqcuwkCR1GRaSpC7DQpLUdezQDUzCySefXCtXrhy6DUk6qmzduvVvqmpqtmWvyLBYuXIlW7ZsGboNSTqqJHnqUMs8DSVJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUNbGwSPKaJPcl+WaS7Ul+r9VPT/L1JDNJ/luS41v91W1+pi1fObava1v9sSQXTKpnSdLsJnlk8SLwjqr6OeBMYE2Sc4H/BNxQVT8NPAdc1ta/DHiu1W9o65FkNXAxcAawBviTJMdMsG9J0kEmFhY18v02e1x7FfAO4H+0+i3ARW16bZunLX9nkrT6bVX1YlV9C5gBzp5U35Kkl5roHdztCGAr8NPAjcD/Ab5bVXvbKjuAU9v0qcDTAFW1N8nzwN9v9XvHdju+zfhnrQfWA5x22mnz/rdIWnr++Oo/H7qFibjiw79yxNtMdIC7qvZV1ZnAckZHA/9ogp+1oaqmq2p6amrWR5tIkl6mBbkaqqq+C9wD/DPgxCT7j2iWAzvb9E5gBUBb/veA74zXZ9lGkrQAJnk11FSSE9v0a4F3AY8yCo3faKutAz7Xpje1edryv6zRD4RvAi5uV0udDqwC7ptU35Kkl5rkmMUy4JY2bvEq4Paq+nySR4DbkvxH4BvAzW39m4E/TTID7GF0BRRVtT3J7cAjwF7g8qraN8G+JUkHmVhYVNWDwFmz1J9glquZqurvgN88xL6uB66f7x4lSXPjHdySpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpK6JhUWSFUnuSfJIku1Jrmz1DyTZmWRbe104ts21SWaSPJbkgrH6mlabSXLNpHqWJM3u2Anuey9wdVU9kOQEYGuSzW3ZDVX1ofGVk6wGLgbOAN4E/EWSn2mLbwTeBewA7k+yqaoemWDvkqQxEwuLqnoGeKZNv5DkUeDUw2yyFritql4EvpVkBji7LZupqicAktzW1jUsJGmBLMiYRZKVwFnA11vpiiQPJtmY5KRWOxV4emyzHa12qPrBn7E+yZYkW3bv3j3Pf4EkLW0TD4skrwfuAK6qqu8BNwE/BZzJ6Mjjw/PxOVW1oaqmq2p6ampqPnYpSWomOWZBkuMYBcWnquozAFX17NjyjwOfb7M7gRVjmy9vNQ5TlyQtgEleDRXgZuDRqvrIWH3Z2Gq/BjzcpjcBFyd5dZLTgVXAfcD9wKokpyc5ntEg+KZJ9S1JeqlJHlmcB7wXeCjJtlb7XeCSJGcCBTwJvB+gqrYnuZ3RwPVe4PKq2geQ5ArgLuAYYGNVbZ9g35Kkg0zyaqivAJll0Z2H2eZ64PpZ6ncebjtJ0mR5B7ckqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1TSwskqxIck+SR5JsT3Jlq78xyeYkj7f3k1o9ST6aZCbJg0neMravdW39x5Osm1TPkqTZTfLIYi9wdVWtBs4FLk+yGrgGuLuqVgF3t3mAdwOr2ms9cBOMwgW4DjgHOBu4bn/ASJIWxsTCoqqeqaoH2vQLwKPAqcBa4Ja22i3ARW16LXBrjdwLnJhkGXABsLmq9lTVc8BmYM2k+pYkvdSCjFkkWQmcBXwdOKWqnmmLvg2c0qZPBZ4e22xHqx2qfvBnrE+yJcmW3bt3z2v/krTUTTwskrweuAO4qqq+N76sqgqo+ficqtpQVdNVNT01NTUfu5QkNRMNiyTHMQqKT1XVZ1r52XZ6ifa+q9V3AivGNl/eaoeqS5IWyCSvhgpwM/BoVX1kbNEmYP8VTeuAz43VL21XRZ0LPN9OV90FnJ/kpDawfX6rSZIWyLET3Pd5wHuBh5Jsa7XfBf4AuD3JZcBTwHvasjuBC4EZ4AfA+wCqak+S3wfub+t9sKr2TLBvSdJBJhYWVfUVIIdY/M5Z1i/g8kPsayOwcf66kyQdCe/gliR1GRaSpK5JjlksSv/03906dAsTsfUPLx26BUmvYB5ZSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSuuYUFknunktNkvTKdNjHfSR5DfATwMnttyT2P0X2Dczy06aSpFem3rOh3g9cBbwJ2MqBsPge8McT7EuStIgcNiyq6o+AP0ryO1X1sQXqSZK0yMzpqbNV9bEk/xxYOb5NVb0yH+EqSfoRcwqLJH8K/BSwDdjXygUYFpK0BMz19yymgdXtp08lSUvMXO+zeBj4h5NsRJK0eM31yOJk4JEk9wEv7i9W1a9OpCtJ0qIy17D4wCSbkCQtbnO9GupLk25EkrR4zfVqqBcYXf0EcDxwHPC3VfWGSTUmSVo85npkccL+6SQB1gLnTqopSdLicsRPna2R/wlccLj1kmxMsivJw2O1DyTZmWRbe104tuzaJDNJHktywVh9TavNJLnmSPuVJP345noa6tfHZl/F6L6Lv+ts9klGz486+Ma9G6rqQwftfzVwMXAGo+dQ/UWSn2mLbwTeBewA7k+yqaoemUvfkqT5MderoX5lbHov8CSjU1GHVFVfTrJyjvtfC9xWVS8C30oyA5zdls1U1RMASW5r6xoWkrSA5jpm8b55/MwrklwKbAGurqrnGD3u/N6xdXZw4BHoTx9UP2e2nSZZD6wHOO200+axXUnSXH/8aHmSz7YxiF1J7kiy/GV83k2MnjF1JvAM8OGXsY9ZVdWGqpququmpqan52q0kibkPcH8C2MRoPOFNwJ+32hGpqmeral9V/RD4OAdONe0EVoyturzVDlWXJC2guYbFVFV9oqr2ttcngSP+53uSZWOzv8bomVMwCqKLk7w6yenAKuA+4H5gVZLTkxzPaBB805F+riTpxzPXAe7vJPkt4NNt/hLgO4fbIMmngbcx+knWHcB1wNuSnMnoBr8nGf0SH1W1PcntjAau9wKXV9W+tp8rgLuAY4CNVbV9zn+dJGlezDUs/iXwMeAGRv+j/9/Abx9ug6q6ZJbyzYdZ/3rg+lnqdwJ3zrFPSdIEzDUsPgisa1cukeSNwIcYhYgk6RVurmMWb94fFABVtQc4azItSZIWm7mGxauSnLR/ph1ZzPWoRJJ0lJvr//A/DHwtyX9v87/JLOMLkqRXprnewX1rki3AO1rp130+kyQtHXM+ldTCwYCQpCXoiB9RLklaegwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkrp8GKCkH/GlX3zr0C1MxFu//KWhWziqeWQhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV0TC4skG5PsSvLwWO2NSTYneby9n9TqSfLRJDNJHkzylrFt1rX1H0+yblL9SpIObZJHFp8E1hxUuwa4u6pWAXe3eYB3A6vaaz1wE4zCBbgOOAc4G7huf8BIkhbOxMKiqr4M7DmovBa4pU3fAlw0Vr+1Ru4FTkyyDLgA2FxVe6rqOWAzLw0gSdKELfSYxSlV9Uyb/jZwSps+FXh6bL0drXao+kskWZ9kS5Itu3fvnt+uJWmJG2yAu6oKqHnc34aqmq6q6ampqfnarSSJhQ+LZ9vpJdr7rlbfCawYW295qx2qLklaQAsdFpuA/Vc0rQM+N1a/tF0VdS7wfDtddRdwfpKT2sD2+a0mSVpAE/ulvCSfBt4GnJxkB6Ormv4AuD3JZcBTwHva6ncCFwIzwA+A9wFU1Z4kvw/c39b7YFUdPGguSZqwiYVFVV1yiEXvnGXdAi4/xH42AhvnsTVJ0hHyDm5JUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUtcgYZHkySQPJdmWZEurvTHJ5iSPt/eTWj1JPppkJsmDSd4yRM+StJQNeWTx9qo6s6qm2/w1wN1VtQq4u80DvBtY1V7rgZsWvFNJWuIW02motcAtbfoW4KKx+q01ci9wYpJlQzQoSUvVUGFRwBeTbE2yvtVOqapn2vS3gVPa9KnA02Pb7mi1H5FkfZItSbbs3r17Un1L0pJ07ECf+wtVtTPJPwA2J/mr8YVVVUnqSHZYVRuADQDT09NHtK0k6fAGCYuq2tnedyX5LHA28GySZVX1TDvNtKutvhNYMbb58laT5s15Hztv6BYm4qu/89WhW9ArxIKfhkryuiQn7J8GzgceBjYB69pq64DPtelNwKXtqqhzgefHTldJkhbAEEcWpwCfTbL/8/+sqr6Q5H7g9iSXAU8B72nr3wlcCMwAPwDet/AtS9LStuBhUVVPAD83S/07wDtnqRdw+QK0Jkk6hMV06awkaZEa6mooLQL/94P/ZOgWJuK0//DQ0C1IrzgeWUiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktR11IRFkjVJHksyk+SaofuRpKXkqAiLJMcANwLvBlYDlyRZPWxXkrR0HBVhAZwNzFTVE1X1/4DbgLUD9yRJS0aqaugeupL8BrCmqv5Vm38vcE5VXTG2znpgfZv9WeCxBW/0pU4G/mboJhYJv4sD/C4O8Ls4YDF8Fz9ZVVOzLTh2oTuZlKraAGwYuo9xSbZU1fTQfSwGfhcH+F0c4HdxwGL/Lo6W01A7gRVj88tbTZK0AI6WsLgfWJXk9CTHAxcDmwbuSZKWjKPiNFRV7U1yBXAXcAywsaq2D9zWXCyq02ID87s4wO/iAL+LAxb1d3FUDHBLkoZ1tJyGkiQNyLCQJHUZFhOQZGOSXUkeHrqXISVZkeSeJI8k2Z7kyqF7GkqS1yS5L8k323fxe0P3NLQkxyT5RpLPD93LkJI8meShJNuSbBm6n0NxzGICkvwi8H3g1qr6x0P3M5Qky4BlVfVAkhOArcBFVfXIwK0tuCQBXldV309yHPAV4Mqqunfg1gaT5N8A08AbquqXh+5nKEmeBKaraugb8g7LI4sJqKovA3uG7mNoVfVMVT3Qpl8AHgVOHbarYdTI99vsce21ZP+llmQ58EvAfxm6F82NYaEFkWQlcBbw9WE7GU477bIN2AVsrqol+10A/xn498APh25kESjgi0m2tscWLUqGhSYuyeuBO4Crqup7Q/czlKraV1VnMnoCwdlJluQpyiS/DOyqqq1D97JI/EJVvYXRU7Uvb6exFx3DQhPVzs/fAXyqqj4zdD+LQVV9F7gHWDN0LwM5D/jVdq7+NuAdSf7rsC0Np6p2tvddwGcZPWV70TEsNDFtUPdm4NGq+sjQ/QwpyVSSE9v0a4F3AX81bFfDqKprq2p5Va1k9Oiev6yq3xq4rUEkeV27+IMkrwPOBxblVZSGxQQk+TTwNeBnk+xIctnQPQ3kPOC9jP7luK29Lhy6qYEsA+5J8iCjZ51trqolfcmoADgF+EqSbwL3Af+rqr4wcE+z8tJZSVKXRxaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLKQJS3JVkp8Ym79z/z0X0tHCS2eledBuQExVveRZR0fLU0Wlw/HIQnqZkqxM8liSWxnddXtzki3jv1eR5F8Db2J0Q949rfZkkpPb9o8m+Xjb5ovt7m6S/HySB9uNjH+41H8bRcMzLKQfzyrgT6rqDODqqpoG3gy8Ncmbq+qjwF8Db6+qtx9i+xvb9t8F/kWrfwJ4f3vw4L6J/xVSh2Eh/XieGvsBo/ckeQD4BnAGsHoO23+rqra16a3AyjaecUJVfa3V/2xeO5ZehmOHbkA6yv0tQJLTgX8L/HxVPZfkk8Br5rD9i2PT+4DXznuH0jzwyEKaH29gFBzPJzmF0W8T7PcCcMJcd9QeYf5CknNa6eJ561J6mTyykOZBVX0zyTcYPXb8aeCrY4s3AF9I8teHGLeYzWXAx5P8EPgS8Py8NiwdIS+dlRahJK/f/5vdSa4BllXVlQO3pSXMIwtpcfqlJNcy+m/0KeC3h21HS51HFpKkLge4JUldhoUkqcuwkCR1GRaSpC7DQpLU9f8B0oQxpJmwnOMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXROAlq_wgWt"
      },
      "source": [
        "We can club ratings 1 and 2 as negative and remaining 3 as positive since we're performing binary classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjxXfHpFwVjJ",
        "outputId": "1bbebd27-ff86-4c24-d283-90a03147ebfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "print(\"SHAPE::\",df.shape)\n",
        "\n",
        "df.rating = df.rating.apply(lambda x : 0 if x<=2 else 1)\n",
        "\n",
        "df.head()\n",
        "\n",
        "class_name = ['negative','positive']\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "\n",
        "token_lens = []\n",
        "for txt in tqdm(df.review):\n",
        "  tokens = tokenizer.encode(txt)\n",
        "  token_lens.append(len(tokens))\n",
        "\n",
        "sns.distplot(token_lens)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/6963 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SHAPE:: (6963, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 21%|██        | 1458/6963 [00:00<00:01, 2786.72it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
            "100%|██████████| 6963/6963 [00:03<00:00, 1980.93it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f345c6c9fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRpBA9KfwXxI"
      },
      "source": [
        "as we can see the largest length of sentence is about 500 (not taking into account the outliers) but that length is going out of memory so we will user smaller max_length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNr0YAfjpbel",
        "outputId": "4ce31862-094b-4b35-adcc-022985b6bc6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "#shuffling so that training, testing and validation sets all have review title and review text\n",
        "# df_shuffle = df.sample(frac = 1) \n",
        "# df_train = (df_shuffle.copy())[:5000]\n",
        "# df_val = (df_shuffle.copy())[5000:6000]\n",
        "# df_test = (df_shuffle.copy())[6000:]\n",
        "\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
        "\n",
        "df_train.shape, df_val.shape, df_test.shape\n",
        "\n",
        "f, axs = plt.subplots(1, 3, figsize=(3 * 4, 1 * 3))\n",
        "plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=.25, wspace=0.4)\n",
        "\n",
        "sns.countplot(df_train.rating, ax=axs[0])\n",
        "sns.countplot(df_val.rating, ax=axs[1])\n",
        "sns.countplot(df_test.rating, ax=axs[2])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3470113518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x216 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FUx7vmawo7W"
      },
      "source": [
        "Distribution of all train, validation and test are also same"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzVlizKGwmOc",
        "outputId": "5a077ab3-96e3-4a8c-e081-d5961ae17511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(df_train.rating.values),\n",
        "                                                 df_train.rating.values)\n",
        "\n",
        "class_weights"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.71708155, 3.28897638, 3.18854962, 1.17002801, 0.4687991 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vly1U_cYpi1i"
      },
      "source": [
        "#Starting the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ro_Tx1aw39S"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "\n",
        "model = SentimentClassifier(len(class_name), birt_pretrained = PRE_TRAINED_MODEL_NAME, dropout1 = dropout1, dropout2 = dropout2)\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYKTDjktw5gb"
      },
      "source": [
        "history = defaultdict(list)\n",
        "best_accuracy = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCZerwx4pnCg",
        "outputId": "bdbb0a7a-dbc8-4e49-8f3a-800225b73f1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f0db11d670ff40c98b8db40ecb66f231",
            "6fd4747f26284757afb6e7f0f086bbb8",
            "235129fa92bf4aa1b5394f745ed69dd9",
            "fea9f8193c2c4347922f3317c306ba3c",
            "f4308f25ea3849dc88015b83cc4899ad",
            "7348f3c38a8f45b9a607206ab27a9cf9",
            "5cb5ebbffd7848cdae049bf9f25f8a77",
            "fa268df151b945f4801d460ae5c40b7e",
            "403f1d2c4724401baa7d84f07662e607",
            "cfe6382465d045ce911526998a6ba530",
            "9a8fbd22f687472e99687602fcd442f0",
            "2ca68af02e5349c1922a2566dfb2f079",
            "37d5a2f3f133406b89b4f94642b50942",
            "dfa5a21043184c48acac534add8d6943",
            "9ea3762070104b8aa30053a1cb784688",
            "46f1cf49f7384412a0486c30dfa75284"
          ]
        }
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "    print('-' * 10)\n",
        "    train_acc, train_loss = train_epoch(\n",
        "        model,\n",
        "        train_data_loader,\n",
        "        loss_fn,\n",
        "        optimizer,\n",
        "        device,\n",
        "        scheduler,\n",
        "        len(df_train)\n",
        "    )\n",
        "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "    val_acc, val_loss = eval_model(\n",
        "        model,\n",
        "        val_data_loader,\n",
        "        loss_fn,\n",
        "        device,\n",
        "        len(df_val)\n",
        "    )\n",
        "    print(f'Val loss {val_loss} accuracy {val_acc}')\n",
        "    print()\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    if val_acc > best_accuracy:\n",
        "        #saving model state so that using above hyperparameters, and given state, we can get the model\n",
        "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "        best_accuracy = val_acc"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0db11d670ff40c98b8db40ecb66f231",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "403f1d2c4724401baa7d84f07662e607",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.46734160059735974 accuracy 0.7991381374192004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val loss 0.3194990957325155 accuracy 0.8664752333094042\n",
            "\n",
            "Epoch 2/5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.2924044309112862 accuracy 0.897294709121379\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val loss 0.2699416816573251 accuracy 0.8973438621679828\n",
            "\n",
            "Epoch 3/5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.21399209363997437 accuracy 0.9344026813502514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val loss 0.29422423480586574 accuracy 0.8980617372577172\n",
            "\n",
            "Epoch 4/5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.1605862829237039 accuracy 0.954033995690687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val loss 0.3348596377975561 accuracy 0.8894472361809046\n",
            "\n",
            "Epoch 5/5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.13323820800385403 accuracy 0.9650466842231267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val loss 0.3495725824243643 accuracy 0.8901651112706389\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_WeRLJgxBqz",
        "outputId": "5df0cd48-ba60-45dc-9d54-b3959f092a6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VGaKtjFw_DI"
      },
      "source": [
        "#saving the entire model, even when we do not have model class, we can directly load model from below file\n",
        "torch.save(model, 'sentiment_classifier')\n",
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "test_acc.item()\n",
        "\n",
        "y_review_texts, y_pred, y_pred_probs, y_test = get_test_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQoQjxI5pxKk"
      },
      "source": [
        "#Analyzing model results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggve77XOpzyJ",
        "outputId": "be645790-f82e-4f1e-9ed0-276a32f12cb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_name))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_name, columns=class_name)\n",
        "show_confusion_matrix(df_cm)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.86      0.85       465\n",
            "    positive       0.93      0.92      0.92       928\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.88      0.89      0.89      1393\n",
            "weighted avg       0.90      0.90      0.90      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ut299xRp2k-"
      },
      "source": [
        "#Making predictions using model files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "277IhLDqp6Vm",
        "outputId": "6a7a4777-7d01-4e56-bbe4-8412ed689df5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Make sure device type model was developed on is same as it's being evaluated on\n",
        "#loading model from saved files\n",
        "#from binary file --> loading state dictionary\n",
        "#requires Model Class\n",
        "model = SentimentClassifier(len(class_name), birt_pretrained = PRE_TRAINED_MODEL_NAME, dropout1 = dropout1, dropout2 = dropout2)\n",
        "model.load_state_dict(torch.load('/content/best_model_state.bin'))\n",
        "model.eval()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (drop): Dropout(p=0.5, inplace=False)\n",
              "  (out1): Linear(in_features=768, out_features=128, bias=True)\n",
              "  (drop1): Dropout(p=0.7, inplace=False)\n",
              "  (relu): ReLU()\n",
              "  (out): Linear(in_features=128, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lHJNufBp8np",
        "outputId": "94583df8-ec9b-4a14-eb1f-ca8757b42386",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#from model file\n",
        "#doesn't require Model Class\n",
        "model = torch.load('sentiment_classifier')\n",
        "model.eval()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (drop): Dropout(p=0.5, inplace=False)\n",
              "  (out1): Linear(in_features=768, out_features=128, bias=True)\n",
              "  (drop1): Dropout(p=0.7, inplace=False)\n",
              "  (relu): ReLU()\n",
              "  (out): Linear(in_features=128, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afdqV4mbqBPb"
      },
      "source": [
        "#Predicting for new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zzth1Rauoclj"
      },
      "source": [
        "def get_predictions(review_text):\n",
        "  encoded_review = tokenizer.encode_plus(\n",
        "  review_text,\n",
        "  max_length=MAX_LEN,\n",
        "  add_special_tokens=True,\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',)\n",
        "  input_ids = encoded_review['input_ids'].to(device)\n",
        "  attention_mask = encoded_review['attention_mask'].to(device)\n",
        "  output = model(input_ids, attention_mask)\n",
        "  _, prediction = torch.max(output, dim=1)\n",
        "  return class_name[prediction]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVHWjA9NqGbv",
        "outputId": "c015fa17-4b59-4a16-abe0-db178c665d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df_out = pd.read_csv('/content/predictions.csv', header=None).reset_index(drop=True).rename(columns={0:'review'})\n",
        "df_out.dropna(inplace=True)\n",
        "df_out"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100 % perfect , awesome taste ,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>250 ml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2nd day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2nd instance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>actual drink</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>wow🤓</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>yummy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433</th>\n",
              "      <td>yummy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>434 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                              review\n",
              "0    100 % perfect , awesome taste ,\n",
              "1                             250 ml\n",
              "2                            2nd day\n",
              "3                       2nd instance\n",
              "4                       actual drink\n",
              "..                               ...\n",
              "429                             wow🤓\n",
              "430                              yes\n",
              "431                             yes \n",
              "432                            yummy\n",
              "433                           yummy \n",
              "\n",
              "[434 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh66r2l5qmIu",
        "outputId": "4165e949-f9c7-4cf7-c0de-a86ed9b3e0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "df_out['sentiment'] = df_out.review.apply(lambda x : get_predictions(x))\n",
        "\n",
        "df_out.to_csv('out.csv')\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMl_OsUmtoD-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}